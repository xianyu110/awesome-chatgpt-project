#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é“¾æ¥æ£€æµ‹è„šæœ¬
æ£€æµ‹ README.md ä¸­æ‰€æœ‰é“¾æ¥çš„æœ‰æ•ˆæ€§
"""

import re
import requests
from urllib.parse import urlparse
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime
import json
import time

# é…ç½®
TIMEOUT = 10  # è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
MAX_WORKERS = 10  # å¹¶å‘çº¿ç¨‹æ•°
RETRY_TIMES = 2  # é‡è¯•æ¬¡æ•°

# ç”¨æˆ·ä»£ç†ï¼Œæ¨¡æ‹Ÿæµè§ˆå™¨è®¿é—®
HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
}

def extract_links_from_markdown(file_path):
    """ä» Markdown æ–‡ä»¶ä¸­æå–æ‰€æœ‰é“¾æ¥"""
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()

    # åŒ¹é… Markdown é“¾æ¥æ ¼å¼ [text](url)
    markdown_links = re.findall(r'\[([^\]]+)\]\(([^\)]+)\)', content)

    # åŒ¹é…çº¯ URL
    url_pattern = r'https?://[^\s\)\]\>]+'
    plain_urls = re.findall(url_pattern, content)

    # åˆå¹¶å¹¶å»é‡
    all_links = {}

    # æ·»åŠ  Markdown æ ¼å¼çš„é“¾æ¥
    for text, url in markdown_links:
        if url.startswith('http'):
            all_links[url] = text

    # æ·»åŠ çº¯ URLï¼ˆä½¿ç”¨ URL æœ¬èº«ä½œä¸ºæ–‡æœ¬ï¼‰
    for url in plain_urls:
        if url not in all_links:
            all_links[url] = url

    return all_links

def check_url(url, retry=RETRY_TIMES):
    """æ£€æŸ¥å•ä¸ª URL çš„æœ‰æ•ˆæ€§"""
    for attempt in range(retry + 1):
        try:
            # å¯¹äºæŸäº›ç‰¹æ®ŠåŸŸåï¼Œä½¿ç”¨ HEAD è¯·æ±‚
            response = requests.head(url, headers=HEADERS, timeout=TIMEOUT, allow_redirects=True)

            # å¦‚æœ HEAD è¯·æ±‚å¤±è´¥ï¼Œå°è¯• GET è¯·æ±‚
            if response.status_code >= 400:
                response = requests.get(url, headers=HEADERS, timeout=TIMEOUT, allow_redirects=True)

            status_code = response.status_code

            if status_code < 400:
                return {
                    'url': url,
                    'status': 'success',
                    'status_code': status_code,
                    'message': 'OK'
                }
            else:
                return {
                    'url': url,
                    'status': 'failed',
                    'status_code': status_code,
                    'message': f'HTTP {status_code}'
                }

        except requests.exceptions.Timeout:
            if attempt < retry:
                time.sleep(1)
                continue
            return {
                'url': url,
                'status': 'failed',
                'status_code': None,
                'message': 'Timeout'
            }
        except requests.exceptions.ConnectionError:
            if attempt < retry:
                time.sleep(1)
                continue
            return {
                'url': url,
                'status': 'failed',
                'status_code': None,
                'message': 'Connection Error'
            }
        except Exception as e:
            return {
                'url': url,
                'status': 'failed',
                'status_code': None,
                'message': str(e)
            }

    return {
        'url': url,
        'status': 'failed',
        'status_code': None,
        'message': 'Max retries reached'
    }

def check_links(links_dict):
    """æ‰¹é‡æ£€æµ‹é“¾æ¥"""
    results = []
    total = len(links_dict)

    print(f"å¼€å§‹æ£€æµ‹ {total} ä¸ªé“¾æ¥...\n")

    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        future_to_url = {
            executor.submit(check_url, url): (url, text)
            for url, text in links_dict.items()
        }

        completed = 0
        for future in as_completed(future_to_url):
            url, text = future_to_url[future]
            try:
                result = future.result()
                result['text'] = text
                results.append(result)

                completed += 1
                # æ˜¾ç¤ºè¿›åº¦
                status_icon = 'âœ“' if result['status'] == 'success' else 'âœ—'
                print(f"[{completed}/{total}] {status_icon} {url[:80]}...")

            except Exception as e:
                results.append({
                    'url': url,
                    'text': text,
                    'status': 'failed',
                    'status_code': None,
                    'message': str(e)
                })

    return results

def generate_report(results, output_file='link_check_report.md'):
    """ç”Ÿæˆæ£€æµ‹æŠ¥å‘Š"""
    success_count = sum(1 for r in results if r['status'] == 'success')
    failed_count = len(results) - success_count
    success_rate = (success_count / len(results) * 100) if results else 0

    # æŒ‰çŠ¶æ€åˆ†ç±»
    failed_links = [r for r in results if r['status'] == 'failed']

    # ç”Ÿæˆ Markdown æŠ¥å‘Š
    report = f"""# é“¾æ¥æ£€æµ‹æŠ¥å‘Š

**æ£€æµ‹æ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## ğŸ“Š ç»Ÿè®¡ä¿¡æ¯

- æ€»é“¾æ¥æ•°: {len(results)}
- âœ… æœ‰æ•ˆé“¾æ¥: {success_count}
- âŒ å¤±æ•ˆé“¾æ¥: {failed_count}
- æˆåŠŸç‡: {success_rate:.2f}%

---

## âŒ å¤±æ•ˆé“¾æ¥åˆ—è¡¨

"""

    if failed_links:
        report += "| åºå· | é“¾æ¥æ–‡æœ¬ | URL | é”™è¯¯ä¿¡æ¯ |\n"
        report += "|------|---------|-----|----------|\n"

        for idx, link in enumerate(failed_links, 1):
            text = link['text'][:50] + '...' if len(link['text']) > 50 else link['text']
            url = link['url'][:80] + '...' if len(link['url']) > 80 else link['url']
            message = link['message']
            report += f"| {idx} | {text} | {url} | {message} |\n"
    else:
        report += "ğŸ‰ æ‰€æœ‰é“¾æ¥éƒ½æœ‰æ•ˆï¼\n"

    report += "\n---\n\n## âœ… æœ‰æ•ˆé“¾æ¥åˆ—è¡¨\n\n"

    success_links = [r for r in results if r['status'] == 'success']
    if success_links:
        report += f"å…± {len(success_links)} ä¸ªæœ‰æ•ˆé“¾æ¥\n\n"
        report += "<details>\n<summary>ç‚¹å‡»å±•å¼€æŸ¥çœ‹</summary>\n\n"
        report += "| åºå· | é“¾æ¥æ–‡æœ¬ | URL | çŠ¶æ€ç  |\n"
        report += "|------|---------|-----|--------|\n"

        for idx, link in enumerate(success_links, 1):
            text = link['text'][:50] + '...' if len(link['text']) > 50 else link['text']
            url = link['url'][:80] + '...' if len(link['url']) > 80 else link['url']
            status_code = link.get('status_code', 'N/A')
            report += f"| {idx} | {text} | {url} | {status_code} |\n"

        report += "\n</details>\n"

    # ä¿å­˜æŠ¥å‘Š
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(report)

    print(f"\nâœ… æŠ¥å‘Šå·²ç”Ÿæˆ: {output_file}")

    # åŒæ—¶ä¿å­˜ JSON æ ¼å¼
    json_file = output_file.replace('.md', '.json')
    with open(json_file, 'w', encoding='utf-8') as f:
        json.dump({
            'check_time': datetime.now().isoformat(),
            'total': len(results),
            'success': success_count,
            'failed': failed_count,
            'success_rate': success_rate,
            'results': results
        }, f, ensure_ascii=False, indent=2)

    print(f"âœ… JSON æŠ¥å‘Šå·²ç”Ÿæˆ: {json_file}")

    return success_count, failed_count

def main():
    """ä¸»å‡½æ•°"""
    readme_file = 'README.md'

    print("=" * 60)
    print("README.md é“¾æ¥æ£€æµ‹å·¥å…·")
    print("=" * 60)
    print()

    # æå–é“¾æ¥
    print("ğŸ“ æ­£åœ¨æå–é“¾æ¥...")
    links = extract_links_from_markdown(readme_file)
    print(f"âœ… æå–åˆ° {len(links)} ä¸ªé“¾æ¥\n")

    # æ£€æµ‹é“¾æ¥
    results = check_links(links)

    # ç”ŸæˆæŠ¥å‘Š
    print("\n" + "=" * 60)
    print("ğŸ“Š ç”Ÿæˆæ£€æµ‹æŠ¥å‘Š...")
    success, failed = generate_report(results)

    print("\n" + "=" * 60)
    print(f"âœ… æ£€æµ‹å®Œæˆ!")
    print(f"   æœ‰æ•ˆ: {success} | å¤±æ•ˆ: {failed}")
    print("=" * 60)

if __name__ == '__main__':
    main()
